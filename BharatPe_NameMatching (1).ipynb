{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-5Zp0HGw901",
        "outputId": "8946691c-74c1-4417-b66f-5cbbb517dc02"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Levenshtein\n",
            "  Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein)\n",
            "  Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\n",
            "Successfully installed Levenshtein-0.26.1 rapidfuzz-3.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fuzzywuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGOS3_YMw-IM",
        "outputId": "79276c77-3b9d-45e1-9ab8-d1f758c51774"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Future Scope we can replace this embedding model with our fine tuned embedding model, may be this one or siamese or BERT or Siamese + BERT\n",
        "EMBEDDING MODELS (SEMANTIC TEXTUAL SIMILARITY)\n",
        "name 1 --> Preprocessing 1 --> Embedding Model (Open/Closed Source) --> Embedding 1 --> Cosine Similarity to get Similarity Score  --> weightage --> 0.4 (40% Weightage)\n",
        "name 2 --> Preprocessing 2 --> Embedding Model (Open/Close Source) --> Embedding 2 -->\n",
        "\n",
        "LEVENTHESIN DISTANCE (STRING MATCHING)\n",
        "name 1 --> Preprocessing 1 --> Leventhesisn Distance --> Similarity Score -->  weightage --> 0.2 (20% Weightage) (USE- STRING MATCHING)\n",
        "name 2 --> Preprocessing 2 -->\n",
        "\n",
        "PHONETIC SOUND (SH->D)\n",
        "name 1 --> Preprocessing 1 --> SoundDex/Metaphone --> Similarity Score -->  weightage --> 0.2 (20% Weightage) (USE- FOR THE NAMES HAVING SAME SOUNDS)\n",
        "name 2 --> Preprocessing 2 --> SoundDex/Metaphone\n",
        "\n",
        "JACCARD SIMILARITY (NUMBER OF OCCCURENCES)\n",
        "name 1 --> Preprocessing 1 --> Jaccard Similarity --> Similarity Score -->  weightage --> 0.1 (10% Weightage) (USE- STRING MATCHING)\n",
        "name 2 --> Preprocessing 2 --> Jaccard Similarity\n",
        "\n",
        "FUZZY Wuzzy (RATIO)\n",
        "name 1 --> Preprocessing 1 --> Fuzzy Matching --> Similarity Score -->  weightage --> 0.1 (10% Weightage)\n",
        "name 2 --> Preprocessing 2 --> Fuzzy Matching -->\n",
        "\n",
        "\n",
        "name 1 name2 --> preprocessing\n",
        "fuzzy wuzzy --> score (matchScore)\n",
        "\n",
        "if matchScore>80:\n",
        "  Aman Sharma vs Raman Sharma hight\n",
        "  Amar Sharma vs Aman Sharma\n",
        "\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "KMpOOzbUw-Kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_parent_spouse_name(text):\n",
        "    \"\"\"Remove relationship markers like 'D/O', 'S/O', 'daughter of', 'son of', etc.\"\"\"\n",
        "    return re.sub(r'\\s*(?:s/o|d/o|w/o|so|do|wo|daughter of|son of|wife of|husband of|daughter|son|child of)\\s*[\\w\\s,.]*$', '', text, flags=re.IGNORECASE).strip()\n",
        "\n",
        "# Example usage\n",
        "name = \"SauaravSonOfManmeet\"\n",
        "cleaned_name = remove_parent_spouse_name(name)\n",
        "print(cleaned_name)  # Output: \"Riya\""
      ],
      "metadata": {
        "id": "XAzF2YFHw-Ml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddbf4800-5166-4348-faed-6d1868bc3e60"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sauarav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "COMMON_MUSLIM_SALUTATIONS_MOHAMMAD_REGEX = r\"\\b(mohammad|mohammed|muhamed|mohd|mohamed|mohamad|muhamad|muhammad|muhammed|muhammet|mohamud|mohummad|mohummed|mouhamed|muhamaad|mohammod|mouhamad|mo|md|mahmood|mahmud|ahmad|ahmed|hameed|hamid|hammed|mahd|mahmod|mohd|mouhammed|mohamad|muhmood|mohhammed|muhmamed|mohmed|mohmat|muhmat|mu|m|shaikh|mo)\\b\""
      ],
      "metadata": {
        "id": "MISARZN53zyi"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_common_muslim_variations(text):\n",
        "    \"\"\"Remove common variations of 'Mohammad' and similar names.\"\"\"\n",
        "    return re.sub(COMMON_MUSLIM_SALUTATIONS_MOHAMMAD_REGEX, '', text, flags=re.IGNORECASE).strip()\n",
        "# MD YOUSUF\tMDYOUSUF  KHASEEMSAB\n",
        "# MOHD SALEEM\tSALIM ISLAM SHAIKH\n",
        "name = \"MO BASIM\"\n",
        "cleaned_name = remove_common_muslim_variations(name)\n",
        "print(cleaned_name)  # Output: \"Riya\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRuhjLmn3NjX",
        "outputId": "65b30aae-e3e6-4220-c36b-19c2ef26a8a6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BASIM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# moombatiye"
      ],
      "metadata": {
        "id": "Qwjpho4e8RK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_extra_spaces(name):\n",
        "    \"\"\"Remove extra spaces between words, allowing only one space.\"\"\"\n",
        "    return re.sub(r'\\s+', ' ', name).strip()\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "example_name = \"Singh  Manmeet\"\n",
        "processed_name = remove_extra_spaces(example_name)\n",
        "print(processed_name)  # Output: \"John Doe\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCVC34Ug3Nlw",
        "outputId": "211fd5d3-2116-4d6d-afeb-f37c484a3d0c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Singh Manmeet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zHdSoLUw3NoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xQgwEa4P3Nqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Main Code\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from Levenshtein import distance as levenshtein_distance\n",
        "from fuzzywuzzy import fuzz\n",
        "import jellyfish\n",
        "import re\n",
        "\n",
        "# Regular expressions for different patterns\n",
        "SPECIAL_CHAR_DOT_REGEX = r\"[.]\"\n",
        "SPECIAL_CHARS_REGEX = r\"[-+.^:,_/\\s]+\"  # Allowing whitespace as a separator\n",
        "SALUTATION_REGEX = r\"^(shree|shri|miss|smt|mrs|mr|ms|dr|master|hon|sir|madam|prof|capt|major|rev|fr|br)\\s*\"\n",
        "PARENT_SPOUSE_NAME_REGEX = r\"(?:\\s*(?:s/o|d/o|w/o|so|do|wo|daughter of|son of|wife of|husband of)\\s*)\"\n",
        "COMMON_MUSLIM_SALUTATIONS_MOHAMMAD_REGEX = r\"\\b(mohammad|mohammed|muhamed|mohd|mohamed|mohamad|muhamad|muhammad|muhammed|muhammet|mohamud|mohummad|mohummed|mouhamed|muhamaad|mohammod|mouhamad|mo|md|mahmood|mahmud|ahmad|ahmed|hameed|hamid|hammed|mahd|mahmod|mohd|mouhammed|mohamad|muhmood|mohhammed|muhmamed|mohmed|mohmat|muhmat|mu|m|shaikh|mo)\\b\"\n",
        "COMMON_MIDDLE_NAMES_REGEX = r\"\\b(kumar|kumari|singh|raj|dev|lal|prasad|rani|bai|khan|kumaravel|kanya|krishna|eshwar)\\b\"\n",
        "COMMON_LAST_NAMES_REGEX = r\"\\b(gupta|sharma|verma|rawat|pandey|yadav|mehta|patel|kapoor|malhotra|choudhary|chaudhary|jha|yadav|bhat|nath)\\b\"\n",
        "LAST_NAMES_AGARWAL_VARIANTS_REGEX = r\"\\b(aggarwal|agrawal|agarwal|aggrawal|agarwalla|agarwal)\\b\"\n",
        "\n",
        "def convert_to_lower(name):\n",
        "    return name.lower()\n",
        "\n",
        "def replace_adjacent_duplicates(value):\n",
        "    if isinstance(value, str):\n",
        "        return re.sub(r'(.)\\1+', r'\\1', value)\n",
        "    else:\n",
        "        return value\n",
        "\n",
        "def replace_characters(name):\n",
        "    replacements = {'e': 'i', 'j': 'z', 'v': 'w', 'q': 'k'}\n",
        "    for old, new in replacements.items():\n",
        "        name = name.replace(old, new)\n",
        "    return name\n",
        "\n",
        "def replace_bigrams(name):\n",
        "    replacements = {'ph': 'f', 'gh': 'g', 'th': 't', 'kh': 'k', 'dh': 'd', 'ch': 'c', 'sh': 's', 'au': 'o',\n",
        "                    'bh': 'b', 'ks': 'x', 'ck': 'k', 'ah': 'h', 'wh': 'w', 'wr': 'r'}\n",
        "    for old, new in replacements.items():\n",
        "        name = name.replace(old, new)\n",
        "    return name\n",
        "\n",
        "def remove_extra_spaces(name):\n",
        "    \"\"\"Remove extra spaces between words, allowing only one space.\"\"\"\n",
        "    return re.sub(r'\\s+', ' ', name).strip()\n",
        "\n",
        "\n",
        "def remove_consonant_a(name):\n",
        "    consonants = 'bcdfghjklmnpqrstvwxyz'\n",
        "    new_name = ''\n",
        "    for i in range(len(name)):\n",
        "        if i > 0 and name[i] == 'a' and name[i - 1].lower() in consonants:\n",
        "            continue\n",
        "        new_name += name[i]\n",
        "    return new_name\n",
        "\n",
        "def remove_special_characters(text):\n",
        "    \"\"\"Remove various special characters defined in regex patterns.\"\"\"\n",
        "    text = re.sub(SPECIAL_CHAR_DOT_REGEX, '', text)\n",
        "    text = re.sub(SPECIAL_CHARS_REGEX, '', text)\n",
        "    return text.strip()\n",
        "\n",
        "def remove_salutations(text):\n",
        "    \"\"\"Remove salutations based on regex patterns for titles.\"\"\"\n",
        "    return re.sub(SALUTATION_REGEX, '', text, flags=re.IGNORECASE).strip()\n",
        "\n",
        "def remove_parent_spouse_name(text):\n",
        "    \"\"\"Remove relationship markers like 'D/O', 'S/O', 'daughter of', 'son of', etc.\"\"\"\n",
        "    # Extend the regex to match various phrases and handle case insensitivity\n",
        "    return re.sub(r'\\s*(?:s/o|d/o|w/o|so|do|wo|daughter of|son of|wife of|husband of|daughter|son|child of)\\s*[\\w\\s,.]*$', '', text, flags=re.IGNORECASE).strip()\n",
        "\n",
        "def remove_common_muslim_variations(text):\n",
        "    \"\"\"Remove common variations of 'Mohammad' and similar names.\"\"\"\n",
        "    return re.sub(COMMON_MUSLIM_SALUTATIONS_MOHAMMAD_REGEX, '', text, flags=re.IGNORECASE).strip()\n",
        "\n",
        "def remove_common_middle_names(text):\n",
        "    \"\"\"Remove common middle names such as 'Kumar' and 'Singh'.\"\"\"\n",
        "    return re.sub(COMMON_MIDDLE_NAMES_REGEX, '', text, flags=re.IGNORECASE).strip()\n",
        "\n",
        "def remove_common_last_names(text):\n",
        "    \"\"\"Remove common last names like 'Gupta' and 'Sharma'.\"\"\"\n",
        "    return re.sub(COMMON_LAST_NAMES_REGEX, '', text, flags=re.IGNORECASE).strip()\n",
        "\n",
        "def remove_agarwal_variants(text):\n",
        "    \"\"\"Remove variants of the surname 'Agarwal'.\"\"\"\n",
        "    return re.sub(LAST_NAMES_AGARWAL_VARIANTS_REGEX, '', text, flags=re.IGNORECASE).strip()\n",
        "\n",
        "def remove_stop_words(text):\n",
        "    stop_words = [\n",
        "        'devi', 'dei', 'debi',\n",
        "        'kumar', 'kumaar', 'kumari', 'kumaari', 'kmr', 'kumr',\n",
        "        'bhai', 'bhau', 'bai',\n",
        "        'ben',\n",
        "        'singh', 'kaur',\n",
        "        'Md', 'Mohd', 'Mohammad', 'Mohamad'\n",
        "    ]\n",
        "\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "def preprocess(name):\n",
        "    \"\"\"Process a name through all the defined normalization steps.\"\"\"\n",
        "    name = remove_salutations(name)\n",
        "    name = remove_parent_spouse_name(name)\n",
        "    name = remove_common_muslim_variations(name)\n",
        "    name = remove_common_middle_names(name)\n",
        "    name = remove_common_last_names(name)\n",
        "    name = remove_agarwal_variants(name)\n",
        "    name = convert_to_lower(name)\n",
        "    name = replace_adjacent_duplicates(name)\n",
        "    name = replace_characters(name)\n",
        "    name = replace_bigrams(name)\n",
        "    name = remove_consonant_a(name)\n",
        "    name = remove_special_characters(name)\n",
        "    name = remove_stop_words(name)\n",
        "    name=remove_extra_spaces(name)\n",
        "    return name\n",
        "\n",
        "# Load pre-trained models\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "model = AutoModel.from_pretrained(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "\n",
        "def get_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        embeddings = model(**inputs).last_hidden_state.mean(dim=1)\n",
        "    return embeddings\n",
        "\n",
        "def calculate_cosine_similarity(embedding1, embedding2):\n",
        "    return cosine_similarity(embedding1, embedding2).item()\n",
        "\n",
        "def calculate_levenshtein_similarity(name1, name2):\n",
        "    lev_distance = levenshtein_distance(name1, name2)\n",
        "    max_len = max(len(name1), len(name2))\n",
        "    return (max_len - lev_distance) / max_len if max_len > 0 else 1.0\n",
        "\n",
        "def calculate_phonetic_similarity(name1, name2):\n",
        "    soundex1 = jellyfish.soundex(name1)\n",
        "    soundex2 = jellyfish.soundex(name2)\n",
        "    return jellyfish.jaro_winkler_similarity(soundex1, soundex2)\n",
        "\n",
        "def calculate_jaccard_similarity(name1, name2):\n",
        "    set1 = set(name1)\n",
        "    set2 = set(name2)\n",
        "    intersection = set1.intersection(set2)\n",
        "    union = set1.union(set2)\n",
        "    return len(intersection) / len(union) if union else 1.0\n",
        "\n",
        "def name_match(name1, name2):\n",
        "    name1_processed = preprocess(name1)\n",
        "    name2_processed = preprocess(name2)\n",
        "\n",
        "    embedding1 = get_embedding(name1_processed)\n",
        "    embedding2 = get_embedding(name2_processed)\n",
        "    embedding_similarity = calculate_cosine_similarity(embedding1, embedding2)\n",
        "    print(\"Printing the embedding Similarity \", embedding_similarity)\n",
        "\n",
        "    levenshtein_similarity = calculate_levenshtein_similarity(name1_processed, name2_processed)\n",
        "    print(\"Printing the Levenshtein Similarity \", levenshtein_similarity)\n",
        "\n",
        "    phonetic_similarity = calculate_phonetic_similarity(name1_processed, name2_processed)\n",
        "    print(\"Printing the Phonetic Similarity \", phonetic_similarity)\n",
        "\n",
        "    jaccard_similarity = calculate_jaccard_similarity(name1_processed, name2_processed)\n",
        "    print(\"Printing the Jaccard Similarity \", jaccard_similarity)\n",
        "\n",
        "    fuzzy_ratio = fuzz.ratio(name1_processed, name2_processed) / 100.0\n",
        "    fuzzy_partial_ratio = fuzz.partial_ratio(name1_processed, name2_processed) / 100.0\n",
        "    fuzzy_token_sort_ratio = fuzz.token_sort_ratio(name1_processed, name2_processed) / 100.0\n",
        "    fuzzy_token_set_ratio = fuzz.token_set_ratio(name1_processed, name2_processed) / 100.0\n",
        "\n",
        "    fuzzy_similarity = (fuzzy_ratio + fuzzy_partial_ratio + fuzzy_token_sort_ratio + fuzzy_token_set_ratio) / 4.0\n",
        "    print(\"Printing the Fuzzy Similarity \", fuzzy_similarity)\n",
        "\n",
        "    weight_embedding = 0.4  # Important for capturing semantic similarities\n",
        "    weight_levenshtein = 0.2  # Useful for identifying minor typographical errors\n",
        "    weight_phonetic = 0.15  # Helpful for matching similar-sounding names\n",
        "    weight_jaccard = 0.15  # Good for measuring the overlap of characters\n",
        "    weight_fuzzy = 0.1  # Useful for broader string matching but can be less precise\n",
        "\n",
        "    final_score = (\n",
        "        embedding_similarity * weight_embedding +\n",
        "        levenshtein_similarity * weight_levenshtein +\n",
        "        phonetic_similarity * weight_phonetic +\n",
        "        jaccard_similarity * weight_jaccard +\n",
        "        fuzzy_similarity * weight_fuzzy\n",
        "    )\n",
        "\n",
        "    return final_score\n"
      ],
      "metadata": {
        "id": "v0jKm7EWBIQO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebdc379d-8465-4d9a-8440-1cc76e607f23"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MOHD JAFAR\tJAFAR ENTERPRISES\n",
        "# Example usage\n",
        "# Mr. MOHD MUSHTAQE SHAIKH\tMOHD MUSHTAQUE AHMED\n",
        "# AQEEL AHMED JAHANGEER MOHD\tMr. MOHD  AQEEL  AHMAD\n",
        "name1 = \"AQEEL AHMED JAHANGEER MOHD\"\n",
        "name2 = \"Mr. MOHD  AQEEL  AHMAD\"\n",
        "# MOHD BASIM\tMOBASIM\n",
        "\n",
        "final_score = name_match(name1, name2)\n",
        "\n",
        "# Check if final_score is greater than 75%\n",
        "if final_score > 0.80:\n",
        "    print(\"Name is Matching\")\n",
        "    print(f\"Final Similarity Score: {final_score:.2f} (Threshold: 0.75)\")\n",
        "else:\n",
        "    print(\"Name is Not Matching\")\n",
        "    print(f\"Final Similarity Score: {final_score:.2f} (Threshold: 0.75)\")"
      ],
      "metadata": {
        "id": "XRHzn0aOBITc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bac258f1-ea33-4b1f-bd74-f255739f5ab3"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing the embedding Similarity  0.8607734441757202\n",
            "Printing the Levenshtein Similarity  0.4\n",
            "Printing the Phonetic Similarity  0.8833333333333334\n",
            "Printing the Jaccard Similarity  0.4444444444444444\n",
            "Printing the Fuzzy Similarity  0.6774999999999999\n",
            "Name is Not Matching\n",
            "Final Similarity Score: 0.69 (Threshold: 0.75)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "91 with BAAI/bge-base-en  (English Language Only)\n",
        "86 with BAAI/bge-large-en-v1.5 (English Language Only)\n",
        "91 with BAAI/bge-m3 (Multilingual)\n",
        "90 with BAAI/bge-base-en (English Language Only)\n",
        "0.93 with sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "TbYgPn87BIW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aeFnODIVBIaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8-zKUW4_BIde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jo1wYRXJBIgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gi0wg3tjBAK3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S4aP_P2aBKRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tp0xrWGfBKTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0acWqFB7BKW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CHNCynNlBKZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P3YD36peBKd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VxkTIIK-BKhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_4QEFTHXBKlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Baz2QtrKBKoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4b_BIMsnBKx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5d6Zj7IlBK1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9KvIneN4BK41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sZeLWGm7BK8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D8OdkJ0BBK_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yHTAFtqhBLG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4o3VsKUOBLKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jzKm_rxgBLNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3YNnt3yGBLRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YcjHKyrmBLUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ItrGpEiVBLXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Ci91samBLbO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}